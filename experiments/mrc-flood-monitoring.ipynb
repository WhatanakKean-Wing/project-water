{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Load Data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T06:50:24.507697Z","iopub.status.busy":"2024-09-09T06:50:24.507205Z","iopub.status.idle":"2024-09-09T06:50:42.402429Z","shell.execute_reply":"2024-09-09T06:50:42.401204Z","shell.execute_reply.started":"2024-09-09T06:50:24.507658Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-09 07:23:05.323393: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-09-09 07:23:05.328274: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-09-09 07:23:05.344716: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-09 07:23:05.371090: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-09 07:23:05.377587: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-09 07:23:05.390310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-09 07:23:06.390239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import requests\n","from bs4 import BeautifulSoup\n","import json\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","import lxml"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T06:50:42.404843Z","iopub.status.busy":"2024-09-09T06:50:42.404193Z","iopub.status.idle":"2024-09-09T06:50:46.102223Z","shell.execute_reply":"2024-09-09T06:50:46.099247Z","shell.execute_reply.started":"2024-09-09T06:50:42.404812Z"},"trusted":true},"outputs":[],"source":["LOWER_MEKONG_STATION_CODES =  [\n","    \"STR\", # StungTreng\n","    \"KRA\", # Kratie\n","    \"KOM\", # Kompong Cham\n","    \"PPB\", # Phnom Penh (Bassac)\n","    \"PPP\", # Phnom Penh Port\n","    \"KOH\", # Koh Khel (Bassac)\n","    \"NEA\", # Neak Luong\n","    \"PRE\", # Prek Kdam (Tonle Sap)\n","    \"TCH\", # Tan Chau\n","    \"CDO\", # Chau Doc (Bassac)\n","]\n","BASE_URL = \"http://ffw.mrcmekong.org/fetchwet_st.php?StCode=\"\n","r = requests.get(BASE_URL+LOWER_MEKONG_STATION_CODES[3], verify=False)\n","# soup = BeautifulSoup(r.content, 'html5lib')\n","# body = soup.find('body')\n","data_string = r.content.decode('utf-8')\n","\n","# Convert single quotes and remove any non-JSON parts\n","data_string = data_string.replace('date_gmt:', '\"date_gmt\":')\n","data_string = data_string.replace('Max:', '\"Max\":')\n","data_string = data_string.replace('Min:', '\"Min\":')\n","data_string = data_string.replace('AVG:', '\"AVG\":')\n","data_string = data_string.replace('floodLevel:', '\"floodLevel\":')\n","data_string = data_string.replace('alarmLevel:', '\"alarmLevel\":')\n","for year in range(1992, 2025):\n","    data_string = data_string.replace(f'{year}:', f'\"{year}\":')\n","\n","data_string = data_string.replace(',]', ']')\n","\n","# Now parse it into a list of dictionaries\n","data = json.loads(data_string)\n","\n","# Convert to dataframe\n","df = pd.DataFrame(data)\n","df['date_gmt'] = df['date_gmt'].apply(lambda x: x.split(\"-\")[1]+\"-\"+x.split(\"-\")[2])\n","df['station'] = LOWER_MEKONG_STATION_CODES[3]\n","\n","# Set date_gmt as index \n","df.index = df['date_gmt']\n","\n","df.describe()"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:50:46.103588Z","iopub.status.idle":"2024-09-09T06:50:46.104174Z","shell.execute_reply":"2024-09-09T06:50:46.103903Z","shell.execute_reply.started":"2024-09-09T06:50:46.103881Z"},"trusted":true},"outputs":[],"source":["df_filtered = df[['date_gmt', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024']]\n","df_filtered.set_index('date_gmt', inplace=True)\n","df_filtered.reset_index(inplace=True)\n","df_long = pd.melt(df_filtered, id_vars=['date_gmt'], value_vars=['2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024'],\n","                   var_name='Year', value_name='water_level')\n","df_long['DATE_GMT'] = pd.to_datetime(df_long['date_gmt'] + '-' + df_long['Year'], format='%m-%d-%Y').dt.strftime('%m-%d-%Y')\n","df_long = df_long[['DATE_GMT', 'water_level']]\n","df_non_zero = df_long[df_long['water_level'] != 0]\n","df_non_zero.set_index('DATE_GMT', inplace=True)\n","df_non_zero.index.freq='D'\n","df_non_zero.plot(figsize=(12,6))"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:50:46.105898Z","iopub.status.idle":"2024-09-09T06:50:46.106455Z","shell.execute_reply":"2024-09-09T06:50:46.106202Z","shell.execute_reply.started":"2024-09-09T06:50:46.106179Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Split the dataset into training and testing sets\n","train = df_non_zero.iloc[:1222]\n","test = df_non_zero.iloc[1222:]\n","\n","# Scale the data\n","scaler = MinMaxScaler()\n","scaled_train = scaler.fit_transform(train)  # Fit on train and transform both train and test\n","scaled_test = scaler.transform(test)\n","\n","look_back = 10  # Number of previous time steps to consider for prediction\n","batch_size = 32  # Batch size\n","\n","# Create TimeseriesGenerator for training and testing data\n","train_generator = TimeseriesGenerator(scaled_train, scaled_train, length=look_back, batch_size=batch_size)\n","test_generator = TimeseriesGenerator(scaled_test, scaled_test, length=look_back, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:50:46.107850Z","iopub.status.idle":"2024-09-09T06:50:46.108409Z","shell.execute_reply":"2024-09-09T06:50:46.108154Z","shell.execute_reply.started":"2024-09-09T06:50:46.108132Z"},"trusted":true},"outputs":[],"source":["# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(50, activation='relu', input_shape=(look_back, scaled_train.shape[1])))\n","model.add(Dense(scaled_train.shape[1]))\n","model.compile(optimizer='adam', loss='mse')\n","early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","history = model.fit(train_generator, \n","                    validation_data=test_generator, \n","                    epochs=100, \n","                    callbacks=[early_stop],\n","                    verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:50:46.109756Z","iopub.status.idle":"2024-09-09T06:50:46.110311Z","shell.execute_reply":"2024-09-09T06:50:46.110058Z","shell.execute_reply.started":"2024-09-09T06:50:46.110034Z"},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-09T06:50:46.111965Z","iopub.status.idle":"2024-09-09T06:50:46.112505Z","shell.execute_reply":"2024-09-09T06:50:46.112264Z","shell.execute_reply.started":"2024-09-09T06:50:46.112242Z"},"trusted":true},"outputs":[],"source":["# Evaluate the model on test data\n","loss = model.evaluate(test_generator)\n","print(f\"Test Loss: {loss}\")\n","\n","# Make predictions\n","predictions = model.predict(test_generator)\n","\n","# Inverse scale predictions to original values\n","predictions_inverse = scaler.inverse_transform(predictions)\n","test_data = scaled_test[look_back:]\n","\n","# Inverse scale the predictions and test data to get back the original scale\n","predictions_inverse = scaler.inverse_transform(predictions)\n","original_test_data_inverse = scaler.inverse_transform(test_data)\n","\n","# Plot predicted vs original values\n","plt.figure(figsize=(8, 4))\n","plt.plot(original_test_data_inverse, label='Original Values')\n","plt.plot(predictions_inverse, label='Predicted Values', linestyle='dashed')\n","plt.title('Predicted vs Original Values')\n","plt.xlabel('Time Steps')\n","plt.ylabel('Values')\n","plt.legend()\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
